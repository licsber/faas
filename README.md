# AI æ£€æµ‹å¹³å° - Nuclio FaaS

åŸºäº Nuclio çš„**é€šç”¨ AI æ£€æµ‹ FaaS å¹³å°**ï¼Œæ”¯æŒå¿«é€Ÿéƒ¨ç½²å„ç±» AI æ¨¡å‹æœåŠ¡ï¼ˆå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€OCRã€æ–‡æœ¬åˆ†æç­‰ï¼‰ã€‚

**âœ¨ è®¾è®¡åŸåˆ™**ï¼šä¸€ä¸ªå¹³å°ï¼Œæ— é™æ£€æµ‹èƒ½åŠ›ã€‚æ·»åŠ æ–°æ£€æµ‹å™¨å°±åƒåˆ›å»ºä¸€ä¸ªæ–°ç›®å½•ä¸€æ ·ç®€å•ã€‚

---

## âš ï¸ é‡è¦ï¼šè·¨å¹³å°éƒ¨ç½²é™åˆ¶

**nuctl åœ¨ macOS ARM64 ä¸Šè¿è¡Œæ—¶ï¼Œä¼šç”Ÿæˆ ARM64 æ¶æ„çš„é•œåƒï¼Œå³ä½¿ DOCKER_HOST æŒ‡å‘è¿œç¨‹ Linux AMD64 æœåŠ¡å™¨ã€‚**

**è§£å†³æ–¹æ¡ˆ**ï¼šå¿…é¡»åœ¨ç›®æ ‡æ¶æ„çš„æœºå™¨ä¸Šè¿è¡Œ `make deploy`ã€‚

---

## ğŸŒ å›½å†…æœåŠ¡å™¨éƒ¨ç½²é¡»çŸ¥

ç”±äºç½‘ç»œåŸå› ï¼Œä»¥ä¸‹é•œåƒåœ¨å›½å†…æœåŠ¡å™¨å¯èƒ½æ— æ³•æ­£å¸¸æ‹‰å–ï¼Œ**å»ºè®®æå‰é€šè¿‡é•œåƒä»£ç†æˆ–å…¶ä»–æ–¹å¼å‡†å¤‡å¥½**ï¼š

| é•œåƒ | ç”¨é€” | è§¦å‘æ—¶æœº |
|------|------|----------|
| `gcr.io/iguazio/uhttpc:0.0.3-amd64` | Nuclio æ„å»ºæ—¶å†…éƒ¨ä½¿ç”¨ | æ‰§è¡Œ `make deploy` æ—¶è‡ªåŠ¨æ‹‰å– |
| `quay.io/nuclio/dashboard:stable-amd64` | Nuclio Dashboard | æ‰§è¡Œ `make dashboard` æ—¶æ‹‰å– |
| `python:3.12-slim` | CPU ç‰ˆæœ¬åŸºç¡€é•œåƒ | éƒ¨ç½² CPU å‡½æ•°æ—¶æ‹‰å– |
| `nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04` | GPU ç‰ˆæœ¬åŸºç¡€é•œåƒ | éƒ¨ç½² GPU å‡½æ•°æ—¶æ‹‰å– |

### æ‰‹åŠ¨æ‹‰å–ç¤ºä¾‹ï¼ˆéœ€é…ç½®ä»£ç†æˆ–ä½¿ç”¨é•œåƒç«™ï¼‰

```bash
# æ–¹æ³• 1ï¼šé€šè¿‡ä»£ç†æ‹‰å–åé‡æ–°æ‰“æ ‡ç­¾
docker pull gcr.io/iguazio/uhttpc:0.0.3-amd64
docker pull quay.io/nuclio/dashboard:stable-amd64
docker pull python:3.12-slim
docker pull nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# æ–¹æ³• 2ï¼šä½¿ç”¨å›½å†…é•œåƒç«™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
# ä¾‹å¦‚é˜¿é‡Œäº‘ã€ DaoCloud ç­‰æä¾›çš„é•œåƒä»£ç†æœåŠ¡
```

å¦‚æœæ‹‰å–å¤±è´¥ï¼Œéƒ¨ç½²æ—¶ä¼šæŠ¥é”™ï¼š`Error response from daemon: Get "https://gcr.io/v2/": net/http: request canceled while waiting for connection`

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šåœ¨ç›®æ ‡æœåŠ¡å™¨ä¸Šéƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
# SSH åˆ° Linux AMD64 æœåŠ¡å™¨
ssh user@your-server

# å…‹éš†é¡¹ç›®
git clone <your-repo>
cd faas

# å¯åŠ¨ Dashboard
make dashboard

# éƒ¨ç½²æ‰€æœ‰æ£€æµ‹å™¨
make deploy
```

### æ–¹å¼äºŒï¼šæœ¬åœ° macOS æµ‹è¯•ï¼ˆä»…é€‚åˆå•æœºå¼€å‘ï¼‰

```bash
# 1. å®‰è£… colima æˆ– Docker Desktopï¼ˆæ”¯æŒ x86_64 æ¨¡æ‹Ÿï¼‰
brew install colima
colima start --arch x86_64

# 2. éƒ¨ç½²
make dashboard
make deploy
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
faas/
â”œâ”€â”€ functions/              # æ£€æµ‹å™¨å‡½æ•°ç›®å½•
â”‚   â””â”€â”€ nsfw-detector/     # ç¤ºä¾‹ï¼šNSFW å›¾åƒæ£€æµ‹
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ function.yaml      # CPU é…ç½®
â”‚       â””â”€â”€ function-gpu.yaml  # GPU é…ç½®
â”œâ”€â”€ templates/             # æ–°å»ºæ£€æµ‹å™¨æ¨¡æ¿
â”‚   â””â”€â”€ python-detector/   # Python æ£€æµ‹å™¨æ¨¡æ¿
â”œâ”€â”€ Makefile               # ç»Ÿä¸€ç®¡ç†å‘½ä»¤
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Makefile å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ |
|------|------|
| `make help` | æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤ |
| `make dashboard` | å¯åŠ¨ Dashboard |
| `make deploy` | **éƒ¨ç½²æ‰€æœ‰æ£€æµ‹å™¨**ï¼ˆå¿…é¡»åœ¨ç›®æ ‡æ¶æ„æœºå™¨ä¸Šè¿è¡Œï¼‰ |
| `make deploy CUDA=true` | **éƒ¨ç½²æ‰€æœ‰æ£€æµ‹å™¨**ï¼ˆGPU ç‰ˆæœ¬ï¼‰ |
| `make deploy FUNCTION=xxx` | éƒ¨ç½²æŒ‡å®šæ£€æµ‹å™¨ |
| `make deploy FUNCTION=xxx CUDA=true` | éƒ¨ç½²æŒ‡å®šæ£€æµ‹å™¨ï¼ˆGPU ç‰ˆæœ¬ï¼‰ |
| `make list` | åˆ—å‡ºæœ¬åœ°å¯ç”¨æ£€æµ‹å™¨ |
| `make status` | æŸ¥çœ‹æ‰€æœ‰æ£€æµ‹å™¨çŠ¶æ€ |
| `make status FUNCTION=xxx` | æŸ¥çœ‹æŒ‡å®šæ£€æµ‹å™¨çŠ¶æ€ |
| `make clean` | åˆ é™¤æ‰€æœ‰æ£€æµ‹å™¨ |

---

## ğŸ—ï¸ æ·»åŠ æ–°æ£€æµ‹å™¨

### å¿«é€Ÿæ·»åŠ 

```bash
# 1. åˆ›å»ºæ–°æ£€æµ‹å™¨ç›®å½•
cp -r templates/python-detector functions/my-detector

# 2. ä¿®æ”¹é…ç½®ä¸­çš„ name å’Œ description
vi functions/my-detector/function.yaml
vi functions/my-detector/function-gpu.yaml

# 3. å®ç°æ£€æµ‹é€»è¾‘
vi functions/my-detector/main.py

# 4. éƒ¨ç½²æµ‹è¯•
make deploy FUNCTION=my-detector
```

### æ£€æµ‹å™¨æ¨¡æ¿ç»“æ„

```python
# main.py ç¤ºä¾‹ç»“æ„
def init_context(context):
    """åˆå§‹åŒ–æ¨¡å‹ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
    global model
    # åŠ è½½ä½ çš„æ¨¡å‹
    model = load_your_model()

def handler(context, event):
    """å¤„ç†æ¯ä¸ªè¯·æ±‚"""
    # è§£æè¾“å…¥
    data = json.loads(event.body)
    
    # æ‰§è¡Œæ£€æµ‹
    result = model.detect(data['input'])
    
    # è¿”å›ç»“æœ
    return context.Response(
        body=json.dumps({"success": True, "data": result}),
        headers={"Content-Type": "application/json"},
        status_code=200
    )
```

è¯¦è§ `templates/README.md`

---

## ğŸ“¡ è°ƒç”¨æ£€æµ‹å™¨

### è·å–æ£€æµ‹å™¨ç«¯å£

```bash
PORT=$(nuctl get function nsfw-detector -n nuclio -o json | \
  python3 -c "import sys,json;print(json.load(sys.stdin).get('status',{}).get('httpPort',''))")
```

### è°ƒç”¨ç¤ºä¾‹ï¼ˆä»¥ NSFW æ£€æµ‹å™¨ä¸ºä¾‹ï¼‰

```bash
# é€šè¿‡ URL æ£€æµ‹
curl -X POST http://localhost:$PORT \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/image.jpg"}'

# é€šè¿‡ base64 æ£€æµ‹
curl -X POST http://localhost:$PORT \
  -H "Content-Type: application/json" \
  -d '{"image": "base64_encoded_image_data"}'
```

å“åº”æ ¼å¼ï¼ˆå„æ£€æµ‹å™¨å¯èƒ½ä¸åŒï¼‰ï¼š
```json
{
    "success": true,
    "data": {
        "is_nsfw": false,
        "predicted_class": "normal",
        "confidence": 0.9876,
        "scores": {"normal": 0.9876, "nsfw": 0.0124}
    }
}
```

---

## âš™ï¸ é…ç½®è¯´æ˜

| é…ç½® | CPU | GPU |
|------|-----|-----|
| runtime | `python:3.12` | `python:3.12` |
| baseImage | `python:3.12-slim` | `nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04` |

å·²é…ç½®æ¸…å PyPI æºåŠ é€Ÿä¸‹è½½ã€‚

---

## ğŸ› æ•…éšœæ’æŸ¥

### `exec format error`

**åŸå› **ï¼šåœ¨ macOS ARM64 ä¸Šæ„å»ºçš„é•œåƒæ— æ³•åœ¨ Linux AMD64 ä¸Šè¿è¡Œã€‚

**è§£å†³**ï¼šå¿…é¡»åœ¨ç›®æ ‡æ¶æ„çš„æœºå™¨ä¸Šè¿è¡Œ `make deploy`ã€‚

### ç«¯å£å†²çª

**è§£å†³**ï¼šå·²åˆ é™¤å›ºå®šç«¯å£ï¼ŒNuclio è‡ªåŠ¨åˆ†é…ã€‚

### æ„å»ºæ…¢

**è§£å†³**ï¼šå·²é…ç½®æ¸…åæºï¼Œé¦–æ¬¡ä¸‹è½½ PyTorch è¾ƒæ…¢ã€‚

---

## ğŸ“ å†…ç½®æ£€æµ‹å™¨

| æ£€æµ‹å™¨ | åŠŸèƒ½ | æ¨¡å‹ |
|--------|------|------|
| `nsfw-detector` | å›¾åƒå†…å®¹å®‰å…¨æ£€æµ‹ | Falconsai/nsfw_image_detection |

æ¬¢è¿è´¡çŒ®æ›´å¤šæ£€æµ‹å™¨ï¼
